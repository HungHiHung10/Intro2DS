{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4419e910",
   "metadata": {},
   "source": [
    "# **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93454f34",
   "metadata": {},
   "source": [
    "## **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d5999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from fuzzywuzzy import fuzz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be3624",
   "metadata": {},
   "source": [
    "## **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7e2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số dòng dữ liệu: 24121\n",
      "Đã lưu thành công file gộp tại: ../data/raw/full.csv\n"
     ]
    }
   ],
   "source": [
    "input_path = '../data/raw' \n",
    "files = glob.glob(os.path.join(input_path, \"Page*to*.csv\")) \n",
    "\n",
    "# 2. Đọc và gộp các file lại\n",
    "List = []\n",
    "for filename in files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    List.append(df)\n",
    "\n",
    "raw = pd.concat(List, axis=0, ignore_index=True)\n",
    "\n",
    "# 3. Xem sơ qua dữ liệu\n",
    "print(f\"Tổng số dòng dữ liệu: {raw.shape[0]}\")\n",
    "raw.head()\n",
    "\n",
    "# 4. Lưu file gộp ra file CSV mới\n",
    "output_path = '../data/raw/full.csv'\n",
    "\n",
    "# Lưu ý quan trọng: index=False để không lưu thêm cột số thứ tự thừa\n",
    "# encoding='utf-8-sig' để mở bằng Excel không bị lỗi phông tiếng Việt\n",
    "raw.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu thành công file gộp tại: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02780363",
   "metadata": {},
   "source": [
    "## **Convert price & area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64356884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_price(text):\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    \n",
    "    text = str(text).lower().strip()\n",
    "    \n",
    "    if any(word in text for word in ['thương lượng', 'liên hệ', 'call', 'zalo', 'inbox', 'lh', 'gọi']):\n",
    "        return np.nan\n",
    "    \n",
    "    text = re.sub(r'\\b(tháng|đồng|đ|/tháng|/thang|/th)\\b', ' ', text)\n",
    "    \n",
    "    text = text.replace(',', '.')\n",
    "    \n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "    \n",
    "    if any(word in text for word in ['trieu', 'triệu', 'tr', 'triệu', 'millions?', 'm$']):\n",
    "        matches = re.findall(r'(\\d+\\.?\\d*)\\s*(triệu|tr|trieu)', text)\n",
    "        if matches:\n",
    "            return float(matches[0][0])\n",
    "        matches = re.findall(r'(\\d+\\.?\\d*)\\s*(tr|triệu)', text)\n",
    "        if matches:\n",
    "            return float(matches[0][0])\n",
    "    \n",
    "    if numbers:\n",
    "        candidates = []\n",
    "        for num in numbers:\n",
    "            num = num.replace('.', '')\n",
    "            if len(num) >= 6:  # >= 100000\n",
    "                price = float(num) / 1_000_000\n",
    "                candidates.append(round(price, 2))\n",
    "        \n",
    "        if candidates:\n",
    "            return max(candidates)  # min\n",
    "    \n",
    "    matches = re.search(r'(\\d+\\.?\\d*)\\s*k\\b', text)\n",
    "    if matches:\n",
    "        return round(float(matches.group(1)) / 1000, 2)\n",
    "    \n",
    "    matches = re.search(r'\\b(\\d+\\.\\d{1,2})\\b', text)\n",
    "    if matches:\n",
    "        try:\n",
    "            val = float(matches.group(1))\n",
    "            if 0.5 <= val <= 50:  \n",
    "                return val\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "def covert_area(text):\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    text = re.sub(r'm²|m2|\\bmét vuông\\b|\\bm2\\b|\\bm²\\b', 'm2', text)\n",
    "    \n",
    "    matches = re.findall(r'(\\d+\\.?\\d*)\\s*m2', text)\n",
    "    if matches:\n",
    "        return float(matches[-1])  \n",
    "    \n",
    "    matches = re.findall(r'(\\d+)\\s*m2', text)\n",
    "    if not matches:\n",
    "        matches = re.findall(r'(\\d+)m2', text)\n",
    "    \n",
    "    if matches:\n",
    "        return float(matches[-1])\n",
    "    \n",
    "    matches = re.search(r'(?:khoảng|etwa|xấp xỉ)\\s*(\\d+)\\s*m2', text)\n",
    "    if matches:\n",
    "        return float(matches.group(1))\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "raw['price'] = raw['price'].apply(covert_price)\n",
    "raw['area'] = raw['area'].apply(covert_area)\n",
    "\n",
    "# raw.head(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669be73a",
   "metadata": {},
   "source": [
    "## **Extract adddress & street name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.rename(columns={'address': 'location'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0939874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_unicode_vn(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    s = str(text)\n",
    "    fixes = {\n",
    "        'Ờng': 'ường', 'ờng': 'ường', 'Ường': 'ường', 'Trưường': 'Trường', \n",
    "        'ĐưỜng': 'Đường', 'đưỜng': 'đường', 'ĐƯỜNG': 'Đường',\n",
    "        'Phố': 'Phố', 'phố': 'phố', 'TL': 'Tỉnh Lộ', 'QL': 'Quốc Lộ',\n",
    "        'q.': 'Quận ', 'h.': 'Huyện ', 'p.': 'Phường ', 'x.': 'Xã '\n",
    "    }\n",
    "    for wrong, correct in fixes.items():\n",
    "        s = s.replace(wrong, correct)\n",
    "    return s\n",
    "\n",
    "def clean_street(text):\n",
    "    if pd.isna(text) or text == \"UNKNOWN\":\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Regex xóa prefix: ^(đường|phố...) ở ĐẦU CÂU, không phân biệt hoa thường\n",
    "    # Thêm cả các lỗi chính tả phổ biến vào đây\n",
    "    pattern = r'^(đường|phố|đưường|duong|đ|d|đg|ngõ|hẻm|ngách|tỉnh lộ|quốc lộ|tl|ql)\\s+'\n",
    "    \n",
    "    clean_text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Xóa luôn các ký tự rác nếu còn sót (ví dụ: \"Thới Tam Thôn,\" -> \"Thới Tam Thôn\")\n",
    "    clean_text = clean_text.strip(',. ')\n",
    "    \n",
    "    return clean_text.title()\n",
    "\n",
    "# ====================== 3. HÀM EXTRACT STREET (Đã sửa lỗi Logic) ======================\n",
    "def extract_street(address):\n",
    "    if pd.isna(address):\n",
    "        return pd.Series([\"UNKNOWN\", \"UNKNOWN\"])\n",
    "    \n",
    "    # Chuẩn hóa sơ bộ\n",
    "    raw = str(address)\n",
    "    addr = \" \" + fix_unicode_vn(raw).lower() + \" \" \n",
    "    \n",
    "    house_number = \"UNKNOWN\"\n",
    "    street_name = \"UNKNOWN\"\n",
    "    \n",
    "    # === BƯỚC 1: Tách số nhà (Logic cũ của bạn khá ổn) ===\n",
    "    # Thêm case bắt \"Ấp đông 5\" -> coi 5 là số nhà, hoặc coi cả cụm là địa chỉ\n",
    "    # Ở đây mình ưu tiên tìm số trước\n",
    "    house_match = re.search(r'\\b(\\d+[\\d\\/\\-\\.A-Za-z]*)\\b', addr)\n",
    "    if house_match:\n",
    "        cand = house_match.group(1)\n",
    "        # Chỉ lấy nếu độ dài hợp lý (tránh số điện thoại)\n",
    "        if len(cand.replace('/', '').replace('-', '').replace('.', '')) <= 10:\n",
    "            house_number = cand.upper()\n",
    "            # Xóa số nhà khỏi chuỗi để tránh nhiễu tên đường\n",
    "            addr = addr.replace(cand, \" \")\n",
    "\n",
    "    # === BƯỚC 2: Danh sách Prefix (ĐÃ SỬA LỖI THIẾU DẤU PHẨY) ===\n",
    "    street_prefixes = [\n",
    "        'đường', 'duong', 'đuờng', 'đường', 'đg', 'đ',\n",
    "        'phố', 'pho',\n",
    "        'đại lộ', 'dai lo',\n",
    "        'quốc lộ', 'ql', 'quoc lo',\n",
    "        'tỉnh lộ', 'tl', 'tinh lo',\n",
    "        'hẻm', 'hem',\n",
    "        'ngõ', 'ngo',\n",
    "        'đường số', 'duong so',\n",
    "        'ấp', 'ap', # Thêm Ấp vào đây vì Hóc Môn hay dùng Ấp làm tên đường\n",
    "        'thôn', 'xóm'\n",
    "    ]\n",
    "    \n",
    "    # === BƯỚC 3: Regex tìm tên đường (ĐÃ SỬA LOOKAHEAD thêm 'xã') ===\n",
    "    # (?=...) là điều kiện dừng. Mình thêm 'xã', 'thôn', 'ấp' vào để nó cắt đúng chỗ.\n",
    "    stop_words = r',|\\s+phường|\\s+quận|\\s+huyện|\\s+thành phố|\\s+tỉnh|\\s+xã|\\s+thị trấn|\\s+thôn|\\s+ấp|$'\n",
    "    \n",
    "    found = False\n",
    "    for prefix in street_prefixes:\n",
    "        # Regex: Tìm [Prefix] + [Tên đường] + [Dấu hiệu dừng]\n",
    "        pattern = rf'{prefix}\\s+([^,;\\(\\)\\[\\]]+?)(?={stop_words})'\n",
    "        match = re.search(pattern, addr)\n",
    "        if match:\n",
    "            name = match.group(1).strip()\n",
    "            # Nếu tên tìm được quá ngắn (ví dụ \"số\") hoặc là số, bỏ qua\n",
    "            if len(name) > 1 and not name.isdigit():\n",
    "                street_name = name\n",
    "                found = True\n",
    "                break \n",
    "    \n",
    "    # === BƯỚC 4: Fallback (Nếu không tìm thấy bằng prefix) ===\n",
    "    if not found:\n",
    "        # Nếu có chữ \"Phố\" dính liền tên riêng (VD: Phố Huế)\n",
    "        pho_match = re.search(r'phố\\s+([a-zA-Z\\sàáảãạâấầẩẫậăắằẳẵặèéẻẽẹêếềểễệìíỉĩịòóỏõọôốồổỗộơớờởỡợùúủũụưứừửữựỳýỷỹỵđ]+)', addr)\n",
    "        if pho_match:\n",
    "            street_name = pho_match.group(1)\n",
    "        else:\n",
    "            # Lấy phần đầu tiên của địa chỉ (trước dấu phẩy đầu tiên)\n",
    "            first_part = addr.split(',')[0].strip()\n",
    "            # Clean các từ hành chính nếu lỡ dính vào\n",
    "            for admin in ['phường', 'quận', 'huyện', 'tỉnh', 'xã']:\n",
    "                if admin in first_part:\n",
    "                    first_part = first_part.split(admin)[0]\n",
    "            \n",
    "            if len(first_part) > 2:\n",
    "                street_name = first_part\n",
    "\n",
    "    # === BƯỚC 5: FINAL CLEAN (Quan trọng nhất với bạn) ===\n",
    "    # Chạy hàm clean để xóa \"Đường\", \"Đưường\" còn sót lại\n",
    "    street_name = clean_street(street_name)\n",
    "\n",
    "    return pd.Series([house_number, street_name])\n",
    "def extract_address(location):\n",
    "    if pd.isna(location):\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "    parts = str(location).split(',')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[-2].strip() + ' - ' + parts[-1].strip()\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "raw[['house_number', 'street_name']] = raw['location'].apply(extract_street) \n",
    "raw['address'] = raw['location'].apply(extract_address)\n",
    "# ====================== CHẠY TEST ======================\n",
    "# print(\"Đang xử lý...\")\n",
    "# print(\"\\n=== KẾT QUẢ ===\")\n",
    "# display(raw[['address', 'house_number', 'street_name']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93027f0",
   "metadata": {},
   "source": [
    "## **Adjust interior and amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== BƯỚC 1: Chuẩn hóa văn bản cực mạnh ======================\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Chuyển về lowercase\n",
    "    text = str(text).lower()\n",
    "    # Chuẩn hóa unicode (đảm bảo cả có dấu và không dấu đều match được)\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    # Thay thế biến thể phổ biến\n",
    "    replacements = {\n",
    "        'may lanh': 'máy lạnh', 'maylanh': 'máy lạnh', 'đh': 'điều hòa', 'dh': 'điều hòa',\n",
    "        'ac': 'máy lạnh', 'air': 'máy lạnh', 'máy điều hoà': 'điều hòa',\n",
    "        'tu lanh': 'tủ lạnh', 'tulanh': 'tủ lạnh',\n",
    "        'may giat': 'máy giặt', 'maygiat': 'máy giặt',\n",
    "        'gac lung': 'gác lửng', 'gac cao': 'gác lửng', 'gac xep': 'gác lửng',\n",
    "        'bancol': 'ban công', 'balcony': 'ban công',\n",
    "        'nha xe': 'bãi xe', 'ham xe': 'hầm xe', 'giữ xe': 'bãi xe',\n",
    "        'tu ao': 'tủ quần áo', 'tu quan ao': 'tủ quần áo',\n",
    "        'giuong': 'giường', 'nem': 'nệm', 'ga goi': 'ga gối'\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text\n",
    "\n",
    "# ====================== BƯỚC 2: Từ điển từ khóa SIÊU DÀI + negativeATION ======================\n",
    "# Mỗi tiện ích có 3 danh sách:\n",
    "# - positive: từ khóa khẳng định\n",
    "# - negative: từ khóa phủ định (ví dụ: \"không có máy lạnh\")\n",
    "# - fuzzy_threshold: ngưỡng fuzzy nếu dùng fuzzy matching\n",
    "amenity_keywords = {\n",
    "    'ac': {\n",
    "        'positive': ['máy lạnh', 'điều hòa', 'có máy lạnh', 'có điều hòa', 'máy lạnh inverter', 'máy lạnh mới', 'điều hoà'],\n",
    "        'negative': ['không có máy lạnh', 'không điều hòa', 'không máy lạnh', 'chưa có máy lạnh'],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'fridge': {\n",
    "        'positive': ['tủ lạnh', 'có tủ lạnh', 'tủ lạnh lớn', 'tủ lạnh riêng'],\n",
    "        'negative': ['không tủ lạnh', 'không có tủ lạnh'],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'washing_machine': {\n",
    "        'positive': ['máy giặt', 'có máy giặt', 'máy giặt chung', 'máy giặt riêng', 'giặt sấy'],\n",
    "        'negative': ['không máy giặt', 'không có máy giặt'],\n",
    "        'fuzzy': 85\n",
    "    },\n",
    "    'mezzanine': {\n",
    "        'positive': ['gác', 'gác lửng', 'có gác', 'gác cao', 'gác đúc', 'gác xép', 'duplex', 'phòng gác'],\n",
    "        'negative': ['không gác', 'không có gác'],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'kitchen': {\n",
    "        'positive': ['bếp', 'kệ bếp', 'tủ bếp', 'nấu ăn', 'được nấu ăn', 'nấu nướng', 'bếp riêng', 'bếp từ', 'bếp điện'],\n",
    "        'negative': ['không nấu ăn', 'không được nấu'],\n",
    "        'fuzzy': 85\n",
    "    },\n",
    "    'wardrobe': {\n",
    "        'positive': ['tủ quần áo', 'tủ đồ', 'tủ áo', 'có tủ quần áo'],\n",
    "        'negative': [],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'bed': {\n",
    "        'positive': ['giường', 'nệm', 'có giường', 'giường nệm', 'giường mới'],\n",
    "        'negative': [],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'balcony': {\n",
    "        'positive': ['ban công', 'bancol', 'balcony', 'có ban công', 'view ban công'],\n",
    "        'negative': [],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'elevator': {\n",
    "        'positive': ['thang máy', 'có thang máy', 'tòa nhà thang máy', 'thang máy lên phòng'],\n",
    "        'negative': [],\n",
    "        'fuzzy': 90\n",
    "    },\n",
    "    'free_time': {  # Giờ giấc tự do\n",
    "        'positive': ['giờ giấc tự do', 'tự do giờ giấc', 'giờ thoải mái', 'ra vào tự do', 'không chung chủ'],\n",
    "        'negative': ['giờ giới nghiêm', 'giờ giấc nghiêm ngặt'],\n",
    "        'fuzzy': 85\n",
    "    },\n",
    "    'parking': {\n",
    "        'positive': ['bãi xe', 'hầm xe', 'chỗ để xe', 'giữ xe miễn phí', 'để xe trong nhà', 'hầm để xe'],\n",
    "        'negative': ['không chỗ để xe', 'không để xe'],\n",
    "        'fuzzy': 85\n",
    "    }\n",
    "}\n",
    "\n",
    "# ====================== BƯỚC 3: Hàm kiểm tra cực mạnh ======================\n",
    "def amenity(text, config):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    # 1. Kiểm tra phủ định trước → nếu có là trả 0 luôn\n",
    "    for negative in config['negative']:\n",
    "        if negative in text:\n",
    "            return 0\n",
    "\n",
    "    # 2. Kiểm tra từ khóa chính xác\n",
    "    for positive in config['positive']:\n",
    "        if positive in text:\n",
    "            return 1\n",
    "\n",
    "    # 3. Fuzzy matching (bắt các kiểu viết sai chính tả)\n",
    "    for positive in config['positive']:\n",
    "        clean = positive.lower()\n",
    "        for word in text.split():\n",
    "            if fuzz.ratio(clean, word) >= config.get('fuzzy', 85):\n",
    "                return 1\n",
    "            if fuzz.partial_ratio(clean, word) >= 95:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "for col_name, config in amenity_keywords.items():\n",
    "    raw[col_name] = raw['thongtinmota'].apply(lambda x: amenity(x, config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559246a5",
   "metadata": {},
   "source": [
    "## **Process date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    try:\n",
    "        match = re.search(r'\\d{2}/\\d{2}/\\d{4}', str(date))\n",
    "        if match:\n",
    "            return pd.to_datetime(match.group(), format='%d/%m/%Y')\n",
    "        return pd.to_datetime(date)\n",
    "    except:\n",
    "        return pd.to_datetime(None)\n",
    "\n",
    "raw['date'] = raw['ngaydang'].apply(process_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dedd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313da92a",
   "metadata": {},
   "source": [
    "## **Save result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4745b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'title', 'thongtinmota', 'location', 'address', 'street_name', 'price', 'area', \n",
    "    'date', 'ac', 'fridge',\n",
    "    'washing_machine', 'mezzanine', 'kitchen', 'wardrobe',\n",
    "    'bed', 'balcony', 'elevator', 'free_time', 'parking',\n",
    "    'url'\n",
    "]\n",
    "\n",
    "cleaned = raw[columns].copy()\n",
    "\n",
    "cleaned.rename(columns={'ac': 'air_conditioning'}, inplace=True)\n",
    "cleaned.rename(columns={'thongtinmota': 'description'}, inplace=True)\n",
    "\n",
    "output_path = '../data/cleaned/cleaned_data6.csv'\n",
    "cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"Đã lưu dữ liệu sạch vào: {output_path}\")\n",
    "# print(cleaned.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
