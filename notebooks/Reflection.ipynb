{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3b0db7",
   "metadata": {},
   "source": [
    "# **Reflection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da70f8",
   "metadata": {},
   "source": [
    "### Thành viên: Nguyễn Hữu Khánh Hưng - 23120271\n",
    "\n",
    "- **Khó khăn gặp phải:**  \n",
    "  - Giai đoạn thu thập dữ liệu: Việc crawl từ phongtro123.com gặp nhiều trở ngại như rate limit (bị chặn request sau một số lượng lớn truy cập), dữ liệu không đồng nhất (nhiều bài đăng thiếu tiện ích hoặc mô tả text lộn xộn), và phải xử lý pagination thủ công để thu thập đủ >20.000 records mà không bị block IP.  \n",
    "  - Preprocessing & EDA: Dữ liệu thô có nhiều missing values (đặc biệt ở tiện ích như máy giặt, gác lửng), giá và diện tích cần regex phức tạp để chuyển về float, đồng thời phát hiện outliers (giá phòng \"ảo\" quá cao/thấp do lỗi nhập liệu hoặc đàm phán).  \n",
    "  - Modeling & Tuning: Xây dựng baseline Linear Regression khá đơn giản, nhưng khi tinh chỉnh hyperparameter cho XGBoost và Linear Regression Optimized by ElasticNet (grid/random search với learning_rate, max_depth, n_estimators...) tốn rất nhiều thời gian và tài nguyên tính toán (máy cá nhân chạy chậm, phải thử nhiều lần để tránh overfitting/underfitting).  \n",
    "  - Merge code & README: Khi hợp nhất code từ 4 thành viên, gặp conflict ở một số notebook như `Pre_Processing.ipynb`, phải refactor thủ công để code sạch và chạy ổn định trên mọi máy. Viết README chi tiết cũng mất kha khá thời gian để đảm bảo hướng dẫn tái hiện chính xác.\n",
    "\n",
    "- **Bài học rút ra:**  \n",
    "  - Preprocessing và feature engineering chiếm phần lớn thời gian (khoảng 60–70%) nhưng là yếu tố quyết định chất lượng mô hình – dữ liệu sạch giúp XGBoost đạt R² cao hơn hẳn Linear Regression.  \n",
    "  - Hyperparameter tuning không chỉ là \"thử nhiều\" mà cần chiến lược (bắt đầu từ learning_rate thấp + early stopping, dùng random search trước grid search để tiết kiệm thời gian).  \n",
    "  - Làm việc nhóm hiệu quả nhờ GitHub (branching, pull request, peer review) giúp tránh mất dữ liệu/code và học hỏi lẫn nhau (tôi học được cách xử lý categorical từ bạn Phạm Quốc Khánh, và word-embedding từ bạn Vũ Trần Phúc).  \n",
    "  - README và documentation rõ ràng rất quan trọng – không chỉ để giảng viên chấm mà còn giúp chính mình tái hiện dự án sau này.\n",
    "\n",
    "- **Nếu có thêm thời gian:**  \n",
    "  - Scale dataset lớn hơn bằng cách crawl thêm từ nhatot.com hoặc chotot.com để tăng độ đa dạng dữ liệu và giảm bias.  \n",
    "  - Thử nghiệm ensemble (stacking XGBoost + CatBoost + LightGBM) hoặc thêm Deep learning (MLP với PyTorch) để đẩy R² lên cao hơn.  \n",
    "  - Tích hợp thêm nhiều feature địa lý hơn (khoảng cách đến trường đại học/metro bằng Google Maps API) và deploy mô hình thành web app đơn giản (Streamlit) để dự đoán giá realtime cho sinh viên.  \n",
    "  - Thực hiện A/B testing hoặc cross-validation nâng cao hơn để đánh giá độ ổn định mô hình trên các phân khúc giá khác nhau (phòng dưới 3 triệu vs trên 5 triệu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c9f39",
   "metadata": {},
   "source": [
    "### Thành viên Châu Huỳnh Phúc - 23120329\n",
    "\n",
    "* **Khó khăn gặp phải:**\n",
    "    * **Thách thức về kỹ thuật dữ liệu:** Với vai trò chịu trách nhiệm chính về Processing và Feature Engineering, khó khăn lớn nhất là việc xử lý các dữ liệu thô từ thực tế (website phongtro123.com) thường không nhất quán, chứa nhiều giá trị thiếu và sai lệch. Việc biến đổi các đặc trưng thô thành các biến có ý nghĩa cho mô hình học máy đòi hỏi sự tỉ mỉ và logic cao.\n",
    "    * **Phân tích tương quan phức tạp:** Khi thực hiện ma trận tương quan, việc xác định được đâu là mối liên hệ thực sự có giá trị giữa hàng chục biến số để rút ra insight không hề dễ dàng, đòi hỏi phải quan sát dữ liệu dưới nhiều góc độ khác nhau.\n",
    "    * **Áp lực quản lý:** Việc vừa thực hiện chuyên môn, vừa phải quản lý tiến độ, kiểm soát deadline và báo cáo trạng thái dự án cho cả nhóm đòi hỏi khả năng bao quát và xử lý tình huống linh hoạt để đảm bảo không thành viên nào bị chậm tiến độ.\n",
    "\n",
    "* **Cách vượt qua:**\n",
    "    * **Quy trình hóa công việc:** Áp dụng nghiêm ngặt quy trình CRISP-DM để chia nhỏ các giai đoạn xử lý, giúp việc kiểm soát dữ liệu từ khâu làm sạch đến Feature Engineering trở nên có hệ thống hơn.\n",
    "    * **Tận dụng sức mạnh nhóm:** Sử dụng cơ chế Peer Review (kiểm tra chéo) để các thành viên khác thẩm định lại logic xử lý dữ liệu của mình, giúp phát hiện sớm các lỗi sai sót trong mã nguồn.\n",
    "    * **Công cụ quản lý hiện đại:** Sử dụng triệt để Google Docs, Notion, ... để cập nhật trạng thái hàng tuần và GitHub để quản lý các phiên bản code, giúp việc theo dõi tiến độ của các thành viên (như việc crawl data theo các khoảng ID) trở nên minh bạch và dễ dàng điều chỉnh.\n",
    "\n",
    "* **Điều học được:**\n",
    "    * **Kỹ năng Feature Engineering:** Học được cách trích xuất và tối ưu hóa các đặc trưng quan trọng từ dữ liệu phòng trọ để nâng cao hiệu suất cho các mô hình như XGBoost hay CatBoost mà nhóm đã sử dụng.\n",
    "    * **Tư duy quản trị dự án:** Hiểu được tầm quan trọng của việc lập kế hoạch chi tiết (Milestones) và cách duy trì động lực cho nhóm thông qua việc giao tiếp liên tục trên Zalo và Google Meet.\n",
    "    * **Phân tích chuyên sâu:** Biết cách sử dụng ma trận tương quan và các kỹ thuật thống kê để bóc tách quy luật của thị trường, thay vì chỉ nhìn vào các con số bề nổi.\n",
    "\n",
    "* **Điều bất ngờ:**\n",
    "    * **Sức mạnh của yếu tố thời gian:** Em thực sự bất ngờ khi phân tích câu hỏi số 5 về yếu tố mùa vụ. Sự biến động giá thuê phòng trọ tại TP.HCM theo các cột mốc thời gian trong năm có quy luật rõ ràng hơn nhiều so với dự đoán ban đầu của nhóm.\n",
    "    * **Sự phức tạp của dữ liệu thực:** Dữ liệu thực tế khác xa với các bộ dữ liệu mẫu trong giáo trình; nó đòi hỏi sự can thiệp rất lớn của con người trong khâu tiền xử lý mới có thể đưa vào mô hình hóa.\n",
    "\n",
    "* **Hiểu biết mới về Data Science:**\n",
    "    * **Dữ liệu là cốt lõi:** Em rằng trong một dự án Khoa học dữ liệu, giai đoạn Tiền xử lý và Feature Engineering chiếm đến 80% công sức nhưng cũng chính là yếu tố quyết định sự thành bại của mô hình, chứ không chỉ là việc chọn thuật toán phức tạp.\n",
    "    * **Tính liên ngành:** Data Science không chỉ là lập trình hay toán học, mà còn cần sự am hiểu về lĩnh vực (domain knowledge) – cụ thể trong đồ án này là thị trường bất động sản cho thuê – để có thể đặt ra các câu hỏi nghiên cứu sắc bén và thực tế."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
